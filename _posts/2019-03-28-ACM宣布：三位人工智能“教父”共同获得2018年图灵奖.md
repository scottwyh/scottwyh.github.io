---
layout:     post
title:      ACM:三位人工智能“教父”共同获得2018年图灵奖
subtitle:    "\"深度学习三巨头：Yoshua Bengio、Geoffrey Hinton、Yann LeCun\""
date:       2019-03-28
author:     Captain Nemo
header-img: img/post-bg-2019-ACM-Turing-Award.jpg
catalog: true
tags:
    - 科技
---


## 前言
2019年3月27日，ACM宣布2018年度的图灵奖（A.M Turing Award）颁给三位人工智能“教父”：Yoshua Bengio、Geoffrey Hinton、Yann LeCun，以表彰三人对深度学习神经网络领域所做的重大贡献。图灵奖，又称“计算机界的诺贝尔奖”，一般每年只奖励一名计算机科学家，这是图灵奖1966年设立以来少有的一年颁奖给三位获奖者的情况。

三位科学家创造性的提出了深度学习的基本概念并进行了深度研究，共同引领了人工智能的复兴。现在人工智能是所有科学领域发展最快的领域之一，也是社会上最受关注的话题之一。计算机视觉、语音识别、自然语言处理、自动驾驶汽车等诸多领域的爆炸性发展都离不开深度学习。人工智能的进步和兴盛在很大程度上归功于 Bengio、Hinton 和 LeCun 为深度学习所奠定的基础。

![](https://upload-images.jianshu.io/upload_images/16369454-d145f7c6af9320a2.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 图灵奖得主
### Yann LeCun
![](https://upload-images.jianshu.io/upload_images/16369454-c4151c1e9fac1d59.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
 - 纽约大学教授，Facebook副总裁兼首席人工智能科学家
 - 被誉为“卷积神经网络之父”
 - 主要贡献：
     >  - 发明了卷积神经网络
     > > LeCun于20世纪80年代提出了卷积神经网络，奠定了该领域的基础。他也是首个在手写数字图像上训练卷积神经网络的人。现在，卷积神经网络广泛应用于计算机视觉、语音识别、自然语言处理、自动驾驶汽车、语音合成、图像合成、医学图像分析等众多领域。
     >
     >  - 改进了反向传播算法
     > > LeCun提出了反向传播算法的早期版本（backprop），并根据变分原理对其进行了简洁的推导。
     >
     >  - 拓展了神经网络的应用范围
     > > 早期引入的很多基本的概念现已经成为AI的基础概念。例如，在识别图像的背景下，他研究了如何在神经网络中学习分层特征表示 - 这个概念现在通常用于许多识别任务中。
 

### Geoffrey Hinton
![](https://upload-images.jianshu.io/upload_images/16369454-0446cb16d230a358.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
 - 谷歌副总裁兼谷歌大脑AI团队的高级研究员，多伦多大学名誉教授，Vector Institute 的首席科学顾问
 - 被称为“神经网络之父”
 - 主要贡献：
     >  - 反向传播算法（1986年，Learning Internal Representations by Error Propagation）
     > > 该算法是目前大多数神经网络的计算标准。1986年，Hinton在他的“通过误差传播学习内部表征”一文中证明了反向传播算法允许神经网络发现他们自己的数据内部表示，使得使用神经网络成为可能网络解决以前被认为超出其范围的问题。
     >
     > - 玻尔兹曼机（1983年，Boltzmann Machines）  
     > > 1983年，与Terrence Sejnowski一起，Hinton发明了Boltzmann机器，这是第一个能够学习不属于输入或输出的神经元内部表示的神经网络之一。
     >
     > - 对卷积神经网络进行改进（2012年）
     > > 2012年，Hinton与他的学生Alex Krizhevsky和Ilya Sutskever一起使用整流线性神经元和 dropout正则化改进了卷积神经网络。在着名的ImageNet竞赛中，Hinton和他的学生几乎将对象识别的错误率减半并重塑了计算机视觉领域。

### Yoshua Bengio
![](https://upload-images.jianshu.io/upload_images/16369454-ad1594289c6ad88a.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
 - 蒙特利尔大学计算机科学与运算系教授，魁北克人工智能研究所 Mila 科学主任
 - 人工智能自然语言处理领域的先锋
 - 主要贡献：
     > - 发明序列的概率模型（1990年，Probabilistic models of sequences）
     > > 20世纪90年代，Bengio将神经网络与序列的概率模型相结合，例如隐马尔可夫模型。这些想法被纳入AT＆T / NCR用于阅读手写支票的系统中，被认为是20世纪90年代神经网络研究的巅峰之作，现代深度学习语音识别系统正在扩展这些概念。
     > - 高维词汇嵌入和关注(attention)
     > > 2000年，Bengio撰写了具有里程碑意义的论文“神经概率语言模型”，它引入了高维词嵌入作为词义的表示。 Bengio的见解对自然语言处理任务产生了巨大而持久的影响，包括语言翻译，问答和视觉问答。他的团队还引入了一种注意机制，这种机制导致了机器翻译的突破，并形成了深度学习的顺序处理的关键组成部分。
     > 
     > - 生成性对抗网络(GANs)
     > > 2010年以来，Bengio关于生成性深度学习的论文，特别是与Ian Goodfellow共同开发的生成性对抗网络（GAN），引发了计算机视觉和计算机图形学的革命。在这项工作的一个引人入胜的应用中，计算机实际上可以创建原始图像，让人联想到被认为是人类智能标志的创造力。
     > 
     > - 与 Ian Goodfellow、Aaron Courville 两人合著 《深度学习》一书
     
## 著作权声明
> 本文首次发布于[Nemo's Blog](https://wahz.top/),作者Captain Nemo,转载请保留原文链接。
